{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c9b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e58d0",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25407e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the symbol icons directory\n",
    "\n",
    "model_dir = 'C:/Users/lsreeram/Downloads/_/Hex/AI PID/Model_Dir/03'\n",
    "train_dir = 'C:/Users/lsreeram/Downloads/_/Hex/AI PID/01 Train_Dataset/'\n",
    "test_dir = 'C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset/'\n",
    "pdf_path = 'C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ec30e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "poppler_path=r'C:\\Program Files\\poppler-23.05.0\\bin'\n",
    "pdf_path_ext = 'C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset/Test.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c242a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# Perform one-hot encoding on the labels\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c8ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2858000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eadc769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change_to_test_dir = os.chdir('C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset/')\n",
    "#change_to_pdf_path = os.chdir('C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91dbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--pip install --upgrade tensorflow --user\n",
    "#-----pip install pdf2imageinstall\n",
    "#--pip install opencv-python\n",
    "#--pip install pdf2image\n",
    "#--pip install pdf2image opencv-python\n",
    "##--conda install -c conda-forge poppler\n",
    "#--pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3c1fe",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafeb65",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Training Dataset:\n",
    "    \n",
    "Image type\t\t\tjpeg\n",
    "\n",
    "Dimensions\t\t\t64x64\n",
    "\n",
    "Width x Height\t\t64 pixels\n",
    "\n",
    "Hori x Vert Resolution  96 dpi\n",
    "\n",
    "Bit depth\t\t\t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37129e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the list of symbol icon files\n",
    "symbol_icon_files = os.listdir(train_dir)\n",
    "\n",
    "# Set the input image dimensions\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b0430",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load symbol icons and their labels\n",
    "for symbol_icon_filename in symbol_icon_files:\n",
    "    label, ext = os.path.splitext(symbol_icon_filename)\n",
    "    if ext.lower() in ['.jpeg', '.jpg', '.png']:\n",
    "        label = os.path.splitext(symbol_icon_filename)[0]  # Use the symbol_icon_filename as the label\n",
    "        ext = os.path.splitext(symbol_icon_filename)[1]\n",
    "        image_path = os.path.join(train_dir, symbol_icon_filename)\n",
    "        image = load_img(image_path, target_size=input_shape[:2])\n",
    "        image_array = img_to_array(image)\n",
    "        images.append(image_array)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert the data into NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize the image data\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a9868",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce196406",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37cc19",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(np.unique(labels_encoded)), activation='softmax')  # Number of classes based on unique labels\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b9db7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1849723",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train the CNN model\n",
    "model.fit(images, labels_encoded, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd49164",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(model_dir)\n",
    "# Save the trained model\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445d91c",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the symbol image\n",
    "def preprocess_image(image):\n",
    "    # Resize the image to a consistent size\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    # Normalize the pixel values\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to extract symbols from the PDF image\n",
    "def extract_symbols_from_pdf(pdf_image):\n",
    "    # Apply symbol extraction techniques to obtain symbol images\n",
    "    # This could involve using computer vision techniques like object detection, contour detection, or image segmentation\n",
    "    symbols = []\n",
    "    # Extract symbols from pdf_image and add them to the symbols list\n",
    "    # ...\n",
    "\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03ac948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_IMAGE_SIZE = 1000000  # Maximum image size (in pixels)\n",
    "\n",
    "def extract_symbols_from_pdf(pdf_path):\n",
    "    symbols = []\n",
    "    # Convert PDF pages to images\n",
    "    images = convert_from_path(pdf_path, dpi=300,poppler_path=poppler_path)\n",
    "    \n",
    "    for image in images:\n",
    "        # Convert PIL image to OpenCV format\n",
    "        cv2_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Apply image processing or computer vision techniques to extract symbols\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Check image size\n",
    "        if gray.size > MAX_IMAGE_SIZE:\n",
    "            # Resize the image to a smaller size\n",
    "            ratio = np.sqrt(MAX_IMAGE_SIZE / gray.size)\n",
    "            resized_gray = cv2.resize(gray, (0, 0), fx=ratio, fy=ratio)\n",
    "        else:\n",
    "            resized_gray = gray\n",
    "        # Append extracted symbols to the 'symbols' list\n",
    "        symbols.append(resized_gray)\n",
    "    \n",
    "    return symbols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ccd14d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'resize'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31492\\1648039421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Call the function to extract symbols from the PDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0msymbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_symbols_from_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31492\\1648039421.py\u001b[0m in \u001b[0;36mextract_symbols_from_pdf\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# Process the image to extract symbols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msymbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_symbols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Perform further processing on the extracted symbols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31492\\300275214.py\u001b[0m in \u001b[0;36mextract_symbols\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_symbols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Preprocess the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mpreprocessed_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# Make predictions using the symbol recognition model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31492\\300275214.py\u001b[0m in \u001b[0;36mpreprocess_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Resize the image to the desired input shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mresized_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Normalize the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'resize'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "pdf_path = 'C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset/Test.pdf'\n",
    "def extract_symbols_from_pdf(pdf_path):\n",
    "    symbols = []\n",
    "    # Convert PDF pages to images\n",
    "    images = convert_from_path(pdf_path, poppler_path=poppler_path)\n",
    "\n",
    "    for image in images:\n",
    "        # Process the image to extract symbols\n",
    "        symbols = extract_symbols(image)\n",
    "        # Perform further processing on the extracted symbols\n",
    "\n",
    "    return symbols\n",
    "\n",
    "# Call the function to extract symbols from the PDF\n",
    "symbols = extract_symbols_from_pdf(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d76d9781",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31492\\742357525.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpdf_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpdf_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msymbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_symbols_from_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31492\\381318737.py\u001b[0m in \u001b[0;36mextract_symbols_from_pdf\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msymbols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Convert PDF pages to images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoppler_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpoppler_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pdf2image\\pdf2image.py\u001b[0m in \u001b[0;36mconvert_from_path\u001b[1;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mpoppler_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     page_count = pdfinfo_from_path(\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[0mpdf_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserpw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mownerpw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpoppler_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     )[\"Pages\"]\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pdf2image\\pdf2image.py\u001b[0m in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpoppler_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m             \u001b[0menv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LD_LIBRARY_PATH\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoppler_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\":\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LD_LIBRARY_PATH\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    949\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist2cmdline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist2cmdline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexecutable\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mlist2cmdline\u001b[1;34m(seq)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0mneedquote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfsdecode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m         \u001b[0mbs_buf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mfsdecode\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[1;34m'mbcs'\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwhich\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m         \"\"\"\n\u001b[1;32m--> 822\u001b[1;33m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Does type-checking of `filename`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "# Load the complex engineering drawing PDFs and extract symbols\n",
    "pdf_path = os.chdir('C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset')\n",
    "pdf_image = cv2.imread(pdf_path)\n",
    "symbols = extract_symbols_from_pdf(pdf_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the symbols for prediction\n",
    "preprocessed_symbols = []\n",
    "for symbol in symbols:\n",
    "    preprocessed_symbol = preprocess_image(symbol)\n",
    "    preprocessed_symbols.append(preprocessed_symbol)\n",
    "\n",
    "# Convert the symbols list to a NumPy array\n",
    "symbol_images = np.array(preprocessed_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.chdir('C:/Users/lsreeram/Downloads/_/Hex/AI PID/Model_Dir/01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72613079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = load_model('C:/Users/lsreeram/Downloads/_/Hex/AI PID/Model_Dir/01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions on the symbol images\n",
    "predictions = model.predict(symbol_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the predictions\n",
    "predicted_symbols = []  # List to store the predicted symbols\n",
    "\n",
    "for prediction in predictions:\n",
    "    # Assuming prediction is a one-hot encoded vector\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    predicted_symbols.append(predicted_label)\n",
    "\n",
    "# Associate predicted symbols with their corresponding locations in the original drawing\n",
    "# This step involves integrating the predicted symbols with the appropriate positions or connections in the drawing\n",
    "\n",
    "# Print the predicted symbols\n",
    "for symbol, predicted_symbol in zip(symbols, predicted_symbols):\n",
    "    print(\"Symbol:\", symbol)\n",
    "    print(\"Predicted Symbol:\", predicted_symbol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38119618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the trained model\n",
    "os.chdir('C:/Users/lsreeram/Downloads/_/Hex/AI PID/Model_Dir/02')\n",
    "model = load_model('saved_model.pb')\n",
    "\n",
    "# Function to preprocess the symbol image\n",
    "def preprocess_image(image):\n",
    "    # Resize the image to a consistent size\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    # Normalize the pixel values\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to extract symbols from the PDF image\n",
    "def extract_symbols_from_pdf(pdf_image):\n",
    "    # Apply symbol extraction techniques to obtain symbol images\n",
    "    # This could involve using computer vision techniques like object detection, contour detection, or image segmentation\n",
    "    symbols = []\n",
    "    # Extract symbols from pdf_image and add them to the symbols list\n",
    "    # ...\n",
    "\n",
    "    return symbols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65568493",
   "metadata": {},
   "source": [
    "### Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract symbols from the PDF\n",
    "def extract_symbols_from_pdf(pdf_path_ext):\n",
    "    symbols = []\n",
    "    # Convert PDF pages to images\n",
    "    images = convert_from_path(pdf_path_ext, poppler_path=poppler_path)\n",
    "\n",
    "    # Iterate through the images\n",
    "    for image in images:\n",
    "        # Convert image to grayscale\n",
    "        gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
    "                # Check image size\n",
    "        if gray.size > MAX_IMAGE_SIZE:\n",
    "            # Resize the image to a smaller size\n",
    "            ratio = np.sqrt(MAX_IMAGE_SIZE / gray.size)\n",
    "            resized = cv2.resize(gray, (0, 0), fx=ratio, fy=ratio)\n",
    "        else:\n",
    "            resized = gray\n",
    "\n",
    "\n",
    "        # Apply image processing techniques to extract symbols\n",
    "        # For example, you can use thresholding, contour detection, etc.\n",
    "        # Here's a simple example using thresholding:\n",
    "        _, threshold = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Iterate through the contours and extract symbols as individual images\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            symbol = gray[y:y+h, x:x+w]\n",
    "            symbols.append(symbol)\n",
    "\n",
    "    return symbols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(img):\n",
    "    # Convert the image to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to obtain a binary image\n",
    "    _, binary_img = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour\n",
    "    contour_areas = [cv2.contourArea(contour) for contour in contours]\n",
    "    largest_contour_index = np.argmax(contour_areas)\n",
    "    largest_contour = contours[largest_contour_index]\n",
    "\n",
    "    # Create a mask image for the largest contour\n",
    "    mask = np.zeros_like(gray_img)\n",
    "    cv2.drawContours(mask, [largest_contour], 0, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Apply the mask to the grayscale image\n",
    "    masked_img = cv2.bitwise_and(gray_img, mask)\n",
    "\n",
    "    # Resize the image to the desired input shape\n",
    "    target_size = (32, 32)\n",
    "    if masked_img.shape[0] != 0 and masked_img.shape[1] != 0:  # Check if the image is not empty\n",
    "        resized_img = cv2.resize(masked_img, target_size, interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        resized_img = np.zeros(target_size, dtype=np.uint8)  # Return a black image if the image is empty\n",
    "\n",
    "    # Normalize the pixel values to the range of [0, 1]\n",
    "    normalized_img = resized_img / 255.0\n",
    "\n",
    "    return normalized_img\n",
    "\n",
    "\n",
    "print(pdf_path_ext)\n",
    "for file in os.listdir(test_dir):\n",
    "    print(file)\n",
    "    if file.endswith('.pdf'):\n",
    "        symbols = extract_symbols_from_pdf(pdf_path_ext)\n",
    "\n",
    "        for symbol in symbols:\n",
    "            try:\n",
    "                # Convert symbol to grayscale\n",
    "                symbol_gray = cv2.cvtColor(symbol, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Preprocess the symbol for prediction\n",
    "                preprocessed_symbol = preprocess_image(symbol_gray)\n",
    "                symbol_image = np.expand_dims(preprocessed_symbol, axis=-1)\n",
    "                symbol_image = np.expand_dims(symbol_image, axis=0)\n",
    "\n",
    "                # Perform prediction on the symbol image\n",
    "                if symbol_image.size != 0:  # Check if symbol_image is not empty\n",
    "                    prediction = model.predict(symbol_image)\n",
    "                    predicted_label = np.argmax(prediction)\n",
    "\n",
    "                    # Print the predicted symbol label\n",
    "                    print(\"Symbol:\", symbol)\n",
    "                    print(\"Predicted Label:\", predicted_label)\n",
    "            except Exception as e:\n",
    "                print(\"Error occurred during symbol preprocessing:\", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f7eb9",
   "metadata": {},
   "source": [
    "## New trial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd3d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of symbol icon files\n",
    "symbol_icon_files = os.listdir(train_dir)\n",
    "\n",
    "# Set the input image dimensions\n",
    "input_shape = (32, 32, 3)\n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b047f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store symbol indices and filenames\n",
    "symbol_index_to_filename = {}\n",
    "\n",
    "# Load symbol icons and their labels\n",
    "for i, symbol_icon_filename in enumerate(symbol_icon_files):\n",
    "    label, ext = os.path.splitext(symbol_icon_filename)\n",
    "    if ext.lower() in ['.jpeg', '.jpg', '.png']:\n",
    "        # Add the filename to the dictionary with the corresponding symbol index\n",
    "        symbol_index_to_filename[i] = symbol_icon_filename\n",
    "        label = os.path.splitext(symbol_icon_filename)[0]  # Use the symbol_icon_filename as the label\n",
    "        ext = os.path.splitext(symbol_icon_filename)[1]\n",
    "        image_path = os.path.join(train_dir, symbol_icon_filename)\n",
    "        image = load_img(image_path, target_size=input_shape[:2])\n",
    "        image_array = img_to_array(image)\n",
    "        images.append(image_array)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert the data into NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize the image data\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a33f496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1-Pass Bubl Cap', '1-Pass Gen Tray', '1-Pass Sieve', ...,\n",
       "       'Y Stop Check Valve', 'Y Strainer', '_CC_Line Number w Insu thk'],\n",
       "      dtype='<U67')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479b666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9be6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(np.unique(labels_encoded)), activation='softmax')  # Number of classes based on unique labels\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2458d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b260179a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72/72 [==============================] - 3s 28ms/step - loss: 7.7745 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 7.7432 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 7.7431 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 7.7432 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 7.7431 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 7.7432 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 7.7432 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 7.7432 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 7.7432 - accuracy: 4.3516e-04\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 7.7432 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218af5a8e20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the CNN model\n",
    "model.fit(images, labels_encoded, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e340ee00",
   "metadata": {},
   "source": [
    "#### Create a CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(set(labels)), activation='softmax'))\n",
    "\n",
    "##### Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e31a25e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1968192   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2298)              149370    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,118,458\n",
      "Trainable params: 2,118,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "174d4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert PDF to images\n",
    "def convert_pdf_to_images(sample_path):\n",
    "    images = []\n",
    "    # Convert each page of the PDF to an image\n",
    "    pages = convert_from_path(sample_path, poppler_path=poppler_path)\n",
    "    for page in pages:\n",
    "        # Convert PIL image to numpy array\n",
    "        image = np.array(page)\n",
    "        \n",
    "        # Resize the image while preserving aspect ratio\n",
    "        max_dim = 1000\n",
    "        scale = min(max_dim / image.shape[0], max_dim / image.shape[1])\n",
    "        new_size = (int(image.shape[1] * scale), int(image.shape[0] * scale))\n",
    "        resized_image = cv2.resize(image, new_size)\n",
    "        \n",
    "        images.append(resized_image)\n",
    "    return images\n",
    "\n",
    "\n",
    "# Define the input shape expected by the model\n",
    "input_shape = (32, 32)\n",
    "input_shape = (64,64)\n",
    "\n",
    "# Define a function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    # Resize the image to the desired input shape\n",
    "    resized_image = cv2.resize(image, input_shape[:2])\n",
    "    \n",
    "    # Normalize the image\n",
    "    normalized_image = resized_image / 255.0\n",
    "    \n",
    "    # Add an extra dimension to match the expected input shape of the model\n",
    "    preprocessed_image = np.expand_dims(normalized_image, axis=0)\n",
    "    \n",
    "    return preprocessed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a46b8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the PDF pages\n",
    "pdf_path_ext = 'C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset/Test.pdf'\n",
    "images = convert_pdf_to_images(pdf_path_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94257f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(772, 1000, 3)\n"
     ]
    }
   ],
   "source": [
    "for image in images:\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e35224",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07ba6a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Define the input shape expected by the model\n",
    "input_shape = (32, 32)\n",
    "input_shape = (64,64)\n",
    "\n",
    "# Define a function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    # Resize the image to the desired input shape\n",
    "    resized_image = cv2.resize(image, input_shape[:2])\n",
    "    \n",
    "    # Normalize the image\n",
    "    normalized_image = resized_image / 255.0\n",
    "    \n",
    "    # Add an extra dimension to match the expected input shape of the model\n",
    "    preprocessed_image = np.expand_dims(normalized_image, axis=0)\n",
    "    \n",
    "    return preprocessed_image\n",
    "\n",
    "# Define a function to extract symbols from an image\n",
    "def extract_symbols(image):\n",
    "    # Preprocess the image\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    \n",
    "    # Make predictions using the symbol recognition model\n",
    "    predictions = model.predict(preprocessed_image)\n",
    "    \n",
    "    # Post-processing (e.g., non-maximum suppression, thresholding)\n",
    "    \n",
    "    # Return the extracted symbols\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Loop over the PDF pages\n",
    "pdf_path_ext = 'C:/Users/lsreeram/Downloads/_/Hex/AI PID/02 Test_Dataset/Test.pdf'\n",
    "images = convert_pdf_to_images(pdf_path_ext)\n",
    "\n",
    "for image in images:\n",
    "    predictions = extract_symbols(image)\n",
    "\n",
    "    # Process the extracted symbols (e.g., save, analyze, visualize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c07e9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: [0.00043507 0.00043572 0.00042438 ... 0.00044797 0.00043684 0.00043677]\n",
      "Predicted Symbol: 2035\n"
     ]
    }
   ],
   "source": [
    "# Interpret the predictions\n",
    "predicted_symbols = []  # List to store the predicted symbols\n",
    "\n",
    "for prediction in predictions:\n",
    "    # Assuming prediction is a one-hot encoded vector\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    predicted_symbols.append(predicted_label)\n",
    "\n",
    "# Associate predicted symbols with their corresponding locations in the original drawing\n",
    "# This step involves integrating the predicted symbols with the appropriate positions or connections in the drawing\n",
    "\n",
    "# Print the predicted symbols\n",
    "for symbol, predicted_symbol in zip(predictions, predicted_symbols):\n",
    "    print(\"Symbol:\", symbol)\n",
    "    print(\"Predicted Symbol:\", predicted_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41f96f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Symbol Filename: Alternate Oper P-T Break.Jpeg\n"
     ]
    }
   ],
   "source": [
    "predicted_symbol_index = 1083\n",
    "predicted_symbol_filename = symbol_index_to_filename[predicted_symbol_index]\n",
    "print(\"Predicted Symbol Filename:\", predicted_symbol_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca5632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
