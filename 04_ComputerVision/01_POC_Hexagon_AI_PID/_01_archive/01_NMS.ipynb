{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05a8eae",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082cdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388c813",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e057c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='C:/Users/lsreeram/Downloads/_/Step01_Learning/04_ComputerVision/01_POC_Hexagon_AI_PID/03_train'\n",
    "os.chdir(train_path)\n",
    "\n",
    "#template_path =\"C:/Users/lsreeram/Downloads/_/Step01_Learning/04_ComputerVision/01_POC_Hexagon_AI_PID/03_train/template.jpeg\"\n",
    "#image_path    =\"C:/Users/lsreeram/Downloads/_/Step01_Learning/04_ComputerVision/01_POC_Hexagon_AI_PID/03_train/image.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b459a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_list = ['template (1).png',\n",
    "'template (2).png',\n",
    "'template (3).png',\n",
    "'template (4).png',\n",
    "'template (5).png',\n",
    "'template (6).png']  # Add more template filenames as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcd66245",
   "metadata": {},
   "outputs": [],
   "source": [
    "template ='template (2).png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3d6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_green =(0, 255, 0)\n",
    "color_pink = (255, 105, 180)\n",
    "color_deep_pink = (255, 20, 147)# Pink color (RBG format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9ce95b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and symbol templates\n",
    "image = cv2.imread('5258-601-A1-0414.jpeg', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fa39290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to store the matched templates & locations\n",
    "matched_locations = []\n",
    "matched_templates =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb40e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for matching score\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706e5dd3",
   "metadata": {},
   "source": [
    "# NMS Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32fb8cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_maximum_suppression(image, template, threshold):\n",
    "    # Convert the image and template to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "    _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    # Bounding box coordinates for the detected region\n",
    "    x1 = max_loc[0]\n",
    "    y1 = max_loc[1]\n",
    "    x2 = x1 + template.shape[1]\n",
    "    y2 = y1 + template.shape[0]\n",
    "    \n",
    "    # Calculate the overlap area of the selected bounding box with the remaining bounding boxes\n",
    "    selected_box_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    remaining_boxes_area = (result.shape[1] - template.shape[1] + 1) * \\\n",
    "                           (result.shape[0] - template.shape[0] + 1)\n",
    "    \n",
    "    overlap_area = np.maximum(0, x2 - x1 + 1) * np.maximum(0, y2 - y1 + 1)\n",
    "    \n",
    "    # Calculate the overlap ratio\n",
    "    overlap_ratio = overlap_area / (selected_box_area + remaining_boxes_area - overlap_area)\n",
    "    \n",
    "    if overlap_ratio >= threshold:\n",
    "        return [(x1, y1, x2, y2)]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae60db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Non-Maximum Suppression\n",
    "template = cv2.imread(template_filename, cv2.IMREAD_COLOR)\n",
    "detections = non_maximum_suppression(image, template, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2916872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes around the matched locations on the image\n",
    "for (x1, y1, x2, y2) in detections:\n",
    "    cv2.rectangle(image, (x1,y1), (x2, y2), color_deep_pink,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "616d122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the screen resolution\n",
    "screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "\n",
    "# Resize the image to the desired resolution\n",
    "image_output = cv2.resize(image, (screen_width, screen_height))\n",
    "\n",
    "# Create a named window\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image_output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635cf681",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NMS with exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2089b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def non_maximum_suppression(image, template, threshold):\n",
    "    try:\n",
    "        # Convert the image and template to grayscale\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Perform template matching\n",
    "        result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "        # Bounding box coordinates for the detected region\n",
    "        x1 = max_loc[0]\n",
    "        y1 = max_loc[1]\n",
    "        x2 = x1 + template.shape[1]\n",
    "        y2 = y1 + template.shape[0]\n",
    "        \n",
    "        # Calculate the overlap area of the selected bounding box with the remaining bounding boxes\n",
    "        selected_box_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        remaining_boxes_area = (result.shape[1] - template.shape[1] + 1) * \\\n",
    "                               (result.shape[0] - template.shape[0] + 1)\n",
    "        \n",
    "        overlap_area = np.maximum(0, x2 - x1 + 1) * np.maximum(0, y2 - y1 + 1)\n",
    "        \n",
    "        # Calculate the overlap ratio\n",
    "        overlap_ratio = overlap_area / (selected_box_area + remaining_boxes_area - overlap_area)\n",
    "        \n",
    "        if overlap_ratio >= threshold:\n",
    "            return [(x1, y1, x2, y2)]\n",
    "        else:\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during template matching:\", e)\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276ce31",
   "metadata": {},
   "source": [
    "# Match Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c985af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and symbol templates\n",
    "# Add more templates as needed\n",
    "image = cv2.imread('5258-601-A1-0414.jpeg', cv2.IMREAD_COLOR)\n",
    "template1 = cv2.imread('template1.jpeg', cv2.IMREAD_COLOR)\n",
    "template2 = cv2.imread('template3.jpeg', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to store the matched locations\n",
    "matched_locations = []\n",
    "\n",
    "# Iterate over the symbol templates\n",
    "for template in [template1, template2]:\n",
    "    # Convert the template and image to grayscale\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    # Define a threshold for matching score\n",
    "    threshold = 0.60\n",
    "\n",
    "    # Find locations where the matching score exceeds the threshold\n",
    "    locations = np.where(result >= threshold)\n",
    "    print(locations)\n",
    "\n",
    "    # Iterate over the locations and store the matched rectangles\n",
    "    for loc in zip(*locations[::-1]):\n",
    "        x, y = loc\n",
    "        w, h = template.shape[1], template.shape[0]\n",
    "        matched_locations.append((x, y, x + w, y + h))\n",
    "        print(\"Template found at coordinates (x, y):\", x, y)\n",
    "\n",
    "# Draw bounding boxes around the matched locations on the image\n",
    "for (x1, y1, x2, y2) in matched_locations:\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d0aa4",
   "metadata": {},
   "source": [
    "# imshow settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29256b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a named window\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Get the screen resolution\n",
    "screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "\n",
    "# Calculate the desired window size\n",
    "image_width, image_height = image.shape[1], image.shape[0]\n",
    "window_width = min(screen_width, image_width)\n",
    "window_height = min(screen_height, image_height)\n",
    "\n",
    "# Set the window size\n",
    "cv2.resizeWindow('Image', window_width, window_height)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40499b6",
   "metadata": {},
   "source": [
    "# Print all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be08a3f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Iterate over the templates\n",
    "for template_filename in template_list:\n",
    "    # Read the template image\n",
    "    template = cv2.imread(template_filename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Convert the template and image to grayscale\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    # Define a threshold for matching score\n",
    "    threshold = 0.66\n",
    "\n",
    "    # Find locations where the matching score exceeds the threshold\n",
    "    locations = np.where(result >= threshold)\n",
    "\n",
    "    # Iterate over the locations and store the matched templates\n",
    "    for loc in zip(*locations[::-1]):\n",
    "        matched_templates.append(template_filename)\n",
    "        #print(f\"Template '{template_filename}' found at coordinates (x, y): {loc}\")\n",
    "        x, y = loc\n",
    "        w, h = template.shape[1], template.shape[0]\n",
    "        matched_locations.append((x, y, x + w, y + h))\n",
    "        #print(\"Template found at coordinates (x, y):\", x, y)\n",
    "    \n",
    "# Draw bounding boxes around the matched locations on the image\n",
    "for (x1, y1, x2, y2) in matched_locations:\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color_deep_pink, 2)\n",
    "\n",
    "# Print the list of matched templates\n",
    "#print(\"Matched templates:\")\n",
    "#for template_filename in matched_templates:\n",
    "    #print(template_filename)\n",
    "    \n",
    "# Remove duplicate locations by converting the list to a set\n",
    "unique_locations = set(matched_locations)\n",
    "#for i in unique_locations:\n",
    " #   print(\"location\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94619aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the screen resolution\n",
    "screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "\n",
    "# Resize the image to the desired resolution\n",
    "image = cv2.resize(image, (screen_width, screen_height))\n",
    "\n",
    "# Create a named window\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "## Calculate the desired window size\n",
    "#image_width, image_height = image.shape[1], image.shape[0]\n",
    "#window_width = min(screen_width, image_width)\n",
    "#window_height = min(screen_height, image_height)\n",
    "\n",
    "## Set the window size\n",
    "#cv2.resizeWindow('Image', window_width, window_height)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbcbb37",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Co-ordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad28d31a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Calculate Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100842da",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_x=144044\n",
    "image_y = 9934\n",
    "\n",
    "doc_e = (431.8 , 558.8)\n",
    "doc_x = doc_e[1]\n",
    "doc_y = doc_e[0]\n",
    "scale_x = image_x / doc_x\n",
    "scale_y = image_y / doc_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa53abcc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Calculate Doc x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de279fc5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "document_x1 = x1 / scale_x\n",
    "document_y1 = (image_y - y1) / scale_y\n",
    "document_x2 = x2 / scale_x\n",
    "document_y2 = (image_y - y2) / scale_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f725dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print (document_x1, document_y1, document_x2, document_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742b95a",
   "metadata": {},
   "source": [
    "# SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af240a6",
   "metadata": {},
   "source": [
    "In this modified code, I added the SIFT-related steps to detect and compute keypoints and descriptors for both the image and each template. Then, I used a brute-force matcher (BFMatcher) to match the descriptors between the template and image. Matches were filtered based on distance threshold, and the matched keypoints' coordinates were stored in matched_locations. Finally, bounding boxes were drawn around the matched locations, and the matched templates were printed.\n",
    "\n",
    "Note that you'll need to ensure the template_list is defined and populated with the template filenames. Also, make sure to specify the correct template_width and template_height values to draw the bounding boxes accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d466e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9edb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_list = ['template (1).png',\n",
    "'template (2).png',\n",
    "'template (3).png',\n",
    "'template (4).png',\n",
    "'template (5).png',\n",
    "'template (6).png']  # Add more template filenames as needed\n",
    "\n",
    "# Load the image and symbol templates\n",
    "image = cv2.imread('5258-601-A1-0414.jpeg', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ddf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sift(image):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect and compute keypoints and descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def apply_nms(keypoints, threshold=0.5):\n",
    "    # Sort keypoints by response\n",
    "    keypoints = sorted(keypoints, key=lambda x: x.response, reverse=True)\n",
    "\n",
    "    # Perform non-maximum suppression\n",
    "    nms_keypoints = []\n",
    "    while len(keypoints) > 0:\n",
    "        best_keypoint = keypoints[0]\n",
    "        nms_keypoints.append(best_keypoint)\n",
    "\n",
    "        # Compute overlap area with other keypoints\n",
    "        overlap_areas = []\n",
    "        for i in range(1, len(keypoints)):\n",
    "            overlap_area = (best_keypoint.size ** 2) * threshold\n",
    "            overlap_areas.append(overlap_area)\n",
    "\n",
    "        # Remove keypoints within the overlap area\n",
    "        keypoints = [kpt for kpt, overlap in zip(keypoints, overlap_areas) if kpt.response < overlap]\n",
    "\n",
    "    return nms_keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb558e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SIFT\n",
    "keypoints, descriptors = apply_sift(image)\n",
    "\n",
    "# Apply NMS to keypoints\n",
    "nms_keypoints = apply_nms(keypoints)\n",
    "\n",
    "# Draw keypoints on the image\n",
    "image_with_keypoints = cv2.drawKeypoints(image, nms_keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display the image with keypoints\n",
    "cv2.imshow('SIFT with NMS', image_with_keypoints)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the screen resolution\n",
    "screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "\n",
    "# Resize the image to the desired resolution\n",
    "image_new = cv2.resize(image_with_keypoints, (screen_width, screen_height))\n",
    "\n",
    "# Create a named window\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "## Calculate the desired window size\n",
    "#image_width, image_height = image.shape[1], image.shape[0]\n",
    "#window_width = min(screen_width, image_width)\n",
    "#window_height = min(screen_height, image_height)\n",
    "\n",
    "## Set the window size\n",
    "#cv2.resizeWindow('Image', window_width, window_height)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image_new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe4f57",
   "metadata": {},
   "source": [
    "# SIFT ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89d7a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the template and input image\n",
    "template = cv2.imread('template (2).png', cv2.IMREAD_COLOR)\n",
    "# Load the image and symbol templates\n",
    "image = cv2.imread('5258-601-A1-0414.jpeg', cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "# Convert the template and image to grayscale\n",
    "gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Perform feature matching using SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints_template, descriptors_template = sift.detectAndCompute(gray_template, None)\n",
    "keypoints_image, descriptors_image = sift.detectAndCompute(gray_image, None)\n",
    "\n",
    "# Match the descriptors using a FLANN-based matcher\n",
    "matcher = cv2.FlannBasedMatcher()\n",
    "matches = matcher.knnMatch(descriptors_template, descriptors_image, k=2)\n",
    "\n",
    "# Filter the matches based on the Lowe's ratio test\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.66 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Extract the keypoints for the good matches\n",
    "points_template = np.float32([keypoints_template[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "points_image = np.float32([keypoints_image[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c5e86c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient corresponding points to calculate homography.\n"
     ]
    }
   ],
   "source": [
    "# Ensure that there are at least 4 corresponding points\n",
    "if len(points_template) >= 4 and len(points_image) >= 4:\n",
    "    # Find the homography matrix\n",
    "    M, mask = cv2.findHomography(points_template, points_image, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Apply perspective transformation to the template corners\n",
    "    h, w = template.shape[:2]\n",
    "    template_corners = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "    transformed_corners = cv2.perspectiveTransform(template_corners, M)\n",
    "\n",
    "    # Draw the bounding box on the input image\n",
    "    image_with_box = cv2.polylines(image, [np.int32(transformed_corners)], True, (0, 255, 0), 2)\n",
    "    # Get the screen resolution\n",
    "    screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "    \n",
    "    # Resize the image to the desired resolution\n",
    "    image_new = cv2.resize(image_with_box, (screen_width, screen_height))\n",
    "    # Create a named window\n",
    "    #cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Image with Bounding Box', image_new)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print('Insufficient corresponding points to calculate homography.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371858ea",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the set of unique locations to a list\n",
    "unique_locations_list = list(unique_locations)\n",
    "\n",
    "# Create a list of scores with a value of 1.0 for each location\n",
    "scores = [1.0] * len(unique_locations_list)\n",
    "\n",
    "# Apply non-maximum suppression (NMS) to filter out duplicate locations\n",
    "nms_threshold = 0.66 # Adjust the threshold as needed\n",
    "indices = cv2.dnn.NMSBoxes(unique_locations_list, scores, score_threshold=0.0, nms_threshold=nms_threshold)\n",
    "\n",
    "# Iterate over the indices and draw bounding boxes for the selected locations\n",
    "for i in indices:\n",
    "    (x, y, x2, y2) = unique_locations_list[i]\n",
    "    cv2.rectangle(image, (x, y), (x2, y2), color_deep_pink, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbfa46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to store the matched templates & locations\n",
    "matched_locations = []\n",
    "matched_templates =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ced160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
