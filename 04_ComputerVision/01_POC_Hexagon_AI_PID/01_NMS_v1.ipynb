{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05a8eae",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082cdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388c813",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e057c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='C:/Users/lsreeram/Downloads/_/Step01_Learning/04_ComputerVision/01_POC_Hexagon_AI_PID/03_train'\n",
    "os.chdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcadf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and symbol templates\n",
    "image = cv2.imread('5258-601-A1-0414.jpeg', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b459a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_list = ['template (1).png',\n",
    "'template (2).png',\n",
    "'template (3).png',\n",
    "'template (4).png',\n",
    "'template (5).png',\n",
    "'template (6).png']\n",
    "# Add more template filenames as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0fd76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'template (2).png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da39652",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_green =(0, 255, 0)\n",
    "color_pink = (255, 105, 180)\n",
    "color_deep_pink = (255, 20, 147)# Pink color (RBG format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db79301",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f341ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to store the matched templates & locations\n",
    "matched_locations = []\n",
    "matched_templates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc642ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for matching score\n",
    "threshold = 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bb4d6",
   "metadata": {},
   "source": [
    "# NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3cf89a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the templates\n",
    "for template_filename in template_list:\n",
    "    # Read the template image\n",
    "    template = cv2.imread(template_filename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Convert the template and image to grayscale\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    # Find locations where the matching score exceeds the threshold\n",
    "    locations = np.where(result >= threshold)\n",
    "\n",
    "    # Iterate over the locations and store the matched templates\n",
    "    for loc in zip(*locations[::-1]):\n",
    "        matched_templates.append(template_filename)\n",
    "        #print(f\"Template '{template_filename}' found at coordinates (x, y): {loc}\")\n",
    "        x, y = loc\n",
    "        w, h = template.shape[1], template.shape[0]\n",
    "        matched_locations.append((x, y, x + w, y + h))\n",
    "        #print(\"Template found at coordinates (x, y):\", x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bdb480",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NMS with overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea2294",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def non_maximum_suppression(image, template, threshold):\n",
    "    # Convert the image and template to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "    _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    # Bounding box coordinates for the detected region\n",
    "    x1 = max_loc[0]\n",
    "    y1 = max_loc[1]\n",
    "    x2 = x1 + template.shape[1]\n",
    "    y2 = y1 + template.shape[0]\n",
    "    \n",
    "    # Calculate the overlap area of the selected bounding box with the remaining bounding boxes\n",
    "    selected_box_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    remaining_boxes_area = (result.shape[1] - template.shape[1] + 1) * \\\n",
    "                           (result.shape[0] - template.shape[0] + 1)\n",
    "    \n",
    "    overlap_area = np.maximum(0, x2 - x1 + 1) * np.maximum(0, y2 - y1 + 1)\n",
    "    \n",
    "    # Calculate the overlap ratio\n",
    "    overlap_ratio = overlap_area / (selected_box_area + remaining_boxes_area - overlap_area)\n",
    "    \n",
    "    if overlap_ratio >= threshold:\n",
    "        return [(x1, y1, x2, y2)]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d2ec5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Iterate over the templates\n",
    "for template_filename in template_list:\n",
    "    # Read the template image\n",
    "    template = cv2.imread(template_filename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Perform non-maximum suppression on the matched locations\n",
    "    locations = non_maximum_suppression(image, template, threshold)\n",
    "\n",
    "    # Iterate over the locations and store the matched templates\n",
    "    for loc in locations:\n",
    "        matched_templates.append(template_filename)\n",
    "        matched_locations.append(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49114d92",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NMS with Template Matching Technique/SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07585821",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Iterate over the templates\n",
    "for template_filename in template_list:\n",
    "    # Read the template image\n",
    "    template = cv2.imread(template_filename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Convert the template and image to grayscale\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform SIFT feature extraction on the template and image\n",
    "    keypoints_template, descriptors_template = sift.detectAndCompute(gray_template, None)\n",
    "    keypoints_image, descriptors_image = sift.detectAndCompute(gray_image, None)\n",
    "\n",
    "    # Use FLANN for feature matching\n",
    "    matcher = cv2.FlannBasedMatcher_create()\n",
    "    matches = matcher.knnMatch(descriptors_template, descriptors_image, k=2)\n",
    "\n",
    "    # Apply ratio test to filter good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Extract the coordinates of the matched keypoints\n",
    "    for match in good_matches:\n",
    "        x, y = keypoints_image[match.trainIdx].pt\n",
    "        w, h = template.shape[1], template.shape[0]\n",
    "        matched_templates.append(template_filename)\n",
    "        matched_locations.append((int(x), int(y), int(x + w), int(y + h)))\n",
    "                # Extract the keypoints for the good matches\n",
    "        points_template = np.float32([keypoints_template[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        points_image = np.float32([keypoints_image[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cee594",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ensure that there are at least 4 corresponding points\n",
    "if len(points_template) >= 4 and len(points_image) >= 4:\n",
    "    # Find the homography matrix\n",
    "    M, mask = cv2.findHomography(points_template, points_image, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Apply perspective transformation to the template corners\n",
    "    h, w = template.shape[:2]\n",
    "    template_corners = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "    transformed_corners = cv2.perspectiveTransform(template_corners, M)\n",
    "\n",
    "    # Draw the bounding box on the input image\n",
    "    image_with_box = cv2.polylines(image, [np.int32(transformed_corners)], True, (0, 255, 0), 2)\n",
    "    # Get the screen resolution\n",
    "    screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "    \n",
    "    # Resize the image to the desired resolution\n",
    "    image_new = cv2.resize(image_with_box, (screen_width, screen_height))\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Image with Bounding Box', image_new)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print('Insufficient corresponding points to calculate homography.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64409dc",
   "metadata": {},
   "source": [
    "# Draw Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80261345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes around the matched locations on the image\n",
    "for (x1, y1, x2, y2) in matched_locations:\n",
    "    cv2.rectangle(image, (x1,y1), (x2, y2), color_deep_pink,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5c95c",
   "metadata": {},
   "source": [
    "# Show Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b0bf0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the screen resolution\n",
    "screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "\n",
    "# Resize the image to the desired resolution\n",
    "image_output = cv2.resize(image, (screen_width, screen_height))\n",
    "\n",
    "# Create a named window\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image_output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to store the matched templates & locations\n",
    "matched_locations = []\n",
    "matched_templates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80309e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
