{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05a8eae",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082cdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388c813",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e057c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='C:/Users/lsreeram/Downloads/_/Step01_Learning/04_ComputerVision/01_POC_Hexagon_AI_PID/03_train'\n",
    "os.chdir(train_path)\n",
    "\n",
    "#template_path =\"C:/Users/lsreeram/Downloads/_/Step01_Learning/04_ComputerVision/01_POC_Hexagon_AI_PID/03_train/template.jpeg\"\n",
    "#image_path    =\"C:/Users/lsreeram/Downloads/_/Step01_Learning/04_ComputerVision/01_POC_Hexagon_AI_PID/03_train/image.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706e5dd3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NMS Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb8cfa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def non_maximum_suppression(image, template, threshold):\n",
    "    # Convert the image and template to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "    _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    # Bounding box coordinates for the detected region\n",
    "    x1 = max_loc[0]\n",
    "    y1 = max_loc[1]\n",
    "    x2 = x1 + template.shape[1]\n",
    "    y2 = y1 + template.shape[0]\n",
    "    \n",
    "    # Calculate the overlap area of the selected bounding box with the remaining bounding boxes\n",
    "    selected_box_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    remaining_boxes_area = (result.shape[1] - template.shape[1] + 1) * \\\n",
    "                           (result.shape[0] - template.shape[0] + 1)\n",
    "    \n",
    "    overlap_area = np.maximum(0, x2 - x1 + 1) * np.maximum(0, y2 - y1 + 1)\n",
    "    \n",
    "    # Calculate the overlap ratio\n",
    "    overlap_ratio = overlap_area / (selected_box_area + remaining_boxes_area - overlap_area)\n",
    "    \n",
    "    if overlap_ratio >= threshold:\n",
    "        return [(x1, y1, x2, y2)]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635cf681",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2089b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def non_maximum_suppression(image, template, threshold):\n",
    "    try:\n",
    "        # Convert the image and template to grayscale\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Perform template matching\n",
    "        result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "        # Bounding box coordinates for the detected region\n",
    "        x1 = max_loc[0]\n",
    "        y1 = max_loc[1]\n",
    "        x2 = x1 + template.shape[1]\n",
    "        y2 = y1 + template.shape[0]\n",
    "        \n",
    "        # Calculate the overlap area of the selected bounding box with the remaining bounding boxes\n",
    "        selected_box_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        remaining_boxes_area = (result.shape[1] - template.shape[1] + 1) * \\\n",
    "                               (result.shape[0] - template.shape[0] + 1)\n",
    "        \n",
    "        overlap_area = np.maximum(0, x2 - x1 + 1) * np.maximum(0, y2 - y1 + 1)\n",
    "        \n",
    "        # Calculate the overlap ratio\n",
    "        overlap_ratio = overlap_area / (selected_box_area + remaining_boxes_area - overlap_area)\n",
    "        \n",
    "        if overlap_ratio >= threshold:\n",
    "            return [(x1, y1, x2, y2)]\n",
    "        else:\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during template matching:\", e)\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553f727",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NMS on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1e22c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the image and template\n",
    "image = cv2.imread('5258-601-A1-0414.jpg')\n",
    "template = cv2.imread('template.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75326b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set the threshold for NMS\n",
    "threshold = 0.7\n",
    "\n",
    "# Perform Non-Maximum Suppression\n",
    "detections = non_maximum_suppression(image, template, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f4005",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Draw the bounding boxes on the image\n",
    "for (x1, y1, x2, y2) in detections:\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with bounding boxes\n",
    "cv2.imshow('Image with NMS', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276ce31",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Match Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c985af",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the image and symbol templates\n",
    "# Add more templates as needed\n",
    "image = cv2.imread('5258-601-A1-0414.jpeg', cv2.IMREAD_COLOR)\n",
    "template1 = cv2.imread('template1.jpeg', cv2.IMREAD_COLOR)\n",
    "template2 = cv2.imread('template3.jpeg', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6a6e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define a list to store the matched locations\n",
    "matched_locations = []\n",
    "\n",
    "# Iterate over the symbol templates\n",
    "for template in [template1, template2]:\n",
    "    # Convert the template and image to grayscale\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    # Define a threshold for matching score\n",
    "    threshold = 0.60\n",
    "\n",
    "    # Find locations where the matching score exceeds the threshold\n",
    "    locations = np.where(result >= threshold)\n",
    "    print(locations)\n",
    "\n",
    "    # Iterate over the locations and store the matched rectangles\n",
    "    for loc in zip(*locations[::-1]):\n",
    "        x, y = loc\n",
    "        w, h = template.shape[1], template.shape[0]\n",
    "        matched_locations.append((x, y, x + w, y + h))\n",
    "        print(\"Template found at coordinates (x, y):\", x, y)\n",
    "\n",
    "# Draw bounding boxes around the matched locations on the image\n",
    "for (x1, y1, x2, y2) in matched_locations:\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d0aa4",
   "metadata": {},
   "source": [
    "# imshow settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29256b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a named window\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Get the screen resolution\n",
    "screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "\n",
    "# Calculate the desired window size\n",
    "image_width, image_height = image.shape[1], image.shape[0]\n",
    "window_width = min(screen_width, image_width)\n",
    "window_height = min(screen_height, image_height)\n",
    "\n",
    "# Set the window size\n",
    "cv2.resizeWindow('Image', window_width, window_height)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40499b6",
   "metadata": {},
   "source": [
    "# Print all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b459a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_list = ['template (1).png',\n",
    "'template (2).png',\n",
    "'template (3).png',\n",
    "'template (4).png',\n",
    "'template (5).png',\n",
    "'template (6).png']  # Add more template filenames as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be08a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and symbol templates\n",
    "image = cv2.imread('5258-601-A1-0414.jpeg', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Define a list to store the matched templates & locations\n",
    "matched_locations = []\n",
    "matched_templates =[]\n",
    "\n",
    "# Iterate over the templates\n",
    "for template_filename in template_list:\n",
    "    # Read the template image\n",
    "    template = cv2.imread(template_filename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Convert the template and image to grayscale\n",
    "    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(gray_image, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    # Define a threshold for matching score\n",
    "    threshold = 0.6\n",
    "\n",
    "    # Find locations where the matching score exceeds the threshold\n",
    "    locations = np.where(result >= threshold)\n",
    "\n",
    "    # Iterate over the locations and store the matched templates\n",
    "    for loc in zip(*locations[::-1]):\n",
    "        matched_templates.append(template_filename)\n",
    "        #print(f\"Template '{template_filename}' found at coordinates (x, y): {loc}\")\n",
    "        x, y = loc\n",
    "        w, h = template.shape[1], template.shape[0]\n",
    "        matched_locations.append((x, y, x + w, y + h))\n",
    "        #print(\"Template found at coordinates (x, y):\", x, y)\n",
    "    \n",
    "# Draw bounding boxes around the matched locations on the image\n",
    "for (x1, y1, x2, y2) in matched_locations:\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "# Print the list of matched templates\n",
    "#print(\"Matched templates:\")\n",
    "#for template_filename in matched_templates:\n",
    "    #print(template_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94619aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the screen resolution\n",
    "screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "\n",
    "# Resize the image to the desired resolution\n",
    "image = cv2.resize(image, (screen_width, screen_height))\n",
    "\n",
    "# Create a named window\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "## Calculate the desired window size\n",
    "#image_width, image_height = image.shape[1], image.shape[0]\n",
    "#window_width = min(screen_width, image_width)\n",
    "#window_height = min(screen_height, image_height)\n",
    "\n",
    "## Set the window size\n",
    "#cv2.resizeWindow('Image', window_width, window_height)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbcbb37",
   "metadata": {},
   "source": [
    "# Co-ordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad28d31a",
   "metadata": {},
   "source": [
    "## Calculate Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x=144044\n",
    "image_y = 9934\n",
    "\n",
    "doc_e = (431.8 , 558.8)\n",
    "doc_x = doc_e[1]\n",
    "doc_y = doc_e[0]\n",
    "scale_x = image_x / doc_x\n",
    "scale_y = image_y / doc_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa53abcc",
   "metadata": {},
   "source": [
    "## Calculate Doc x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de279fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_x1 = x1 / scale_x\n",
    "document_y1 = (image_y - y1) / scale_y\n",
    "document_x2 = x2 / scale_x\n",
    "document_y2 = (image_y - y2) / scale_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f725dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.065349476548832 135.0081336823032 17.84510288522951 131.05264747332393\n"
     ]
    }
   ],
   "source": [
    "print (document_x1, document_y1, document_x2, document_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742b95a",
   "metadata": {},
   "source": [
    "# SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af240a6",
   "metadata": {},
   "source": [
    "In this modified code, I added the SIFT-related steps to detect and compute keypoints and descriptors for both the image and each template. Then, I used a brute-force matcher (BFMatcher) to match the descriptors between the template and image. Matches were filtered based on distance threshold, and the matched keypoints' coordinates were stored in matched_locations. Finally, bounding boxes were drawn around the matched locations, and the matched templates were printed.\n",
    "\n",
    "Note that you'll need to ensure the template_list is defined and populated with the template filenames. Also, make sure to specify the correct template_width and template_height values to draw the bounding boxes accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d466e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9edb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_list = ['template (1).png',\n",
    "'template (2).png',\n",
    "'template (3).png',\n",
    "'template (4).png',\n",
    "'template (5).png',\n",
    "'template (6).png']  # Add more template filenames as needed\n",
    "\n",
    "# Load the image and symbol templates\n",
    "image = cv2.imread('5258-601-A1-0414.jpeg', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c3ddf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sift(image):\n",
    "    # Create a SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect and compute keypoints and descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def apply_nms(keypoints, threshold=0.5):\n",
    "    # Sort keypoints by response\n",
    "    keypoints = sorted(keypoints, key=lambda x: x.response, reverse=True)\n",
    "\n",
    "    # Perform non-maximum suppression\n",
    "    nms_keypoints = []\n",
    "    while len(keypoints) > 0:\n",
    "        best_keypoint = keypoints[0]\n",
    "        nms_keypoints.append(best_keypoint)\n",
    "\n",
    "        # Compute overlap area with other keypoints\n",
    "        overlap_areas = []\n",
    "        for i in range(1, len(keypoints)):\n",
    "            overlap_area = (best_keypoint.size ** 2) * threshold\n",
    "            overlap_areas.append(overlap_area)\n",
    "\n",
    "        # Remove keypoints within the overlap area\n",
    "        keypoints = [kpt for kpt, overlap in zip(keypoints, overlap_areas) if kpt.response < overlap]\n",
    "\n",
    "    return nms_keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb558e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SIFT\n",
    "keypoints, descriptors = apply_sift(image)\n",
    "\n",
    "# Apply NMS to keypoints\n",
    "nms_keypoints = apply_nms(keypoints)\n",
    "\n",
    "# Draw keypoints on the image\n",
    "image_with_keypoints = cv2.drawKeypoints(image, nms_keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display the image with keypoints\n",
    "cv2.imshow('SIFT with NMS', image_with_keypoints)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eac22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the screen resolution\n",
    "screen_width, screen_height = 1920, 1080  # Replace with your screen resolution\n",
    "\n",
    "# Resize the image to the desired resolution\n",
    "image_new = cv2.resize(image_with_keypoints, (screen_width, screen_height))\n",
    "\n",
    "# Create a named window\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "## Calculate the desired window size\n",
    "#image_width, image_height = image.shape[1], image.shape[0]\n",
    "#window_width = min(screen_width, image_width)\n",
    "#window_height = min(screen_height, image_height)\n",
    "\n",
    "## Set the window size\n",
    "#cv2.resizeWindow('Image', window_width, window_height)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image_new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe4f57",
   "metadata": {},
   "source": [
    "# SIFT ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d7a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('5258-601-A1-0414.jpeg', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Define the ROI coordinates (x, y, width, height)\n",
    "roi_coords = (100, 100, 200, 200)\n",
    "\n",
    "# Extract the ROI from the image\n",
    "roi = image[roi_coords[1]:roi_coords[1]+roi_coords[3], roi_coords[0]:roi_coords[0]+roi_coords[2]]\n",
    "\n",
    "# Convert the ROI to grayscale\n",
    "gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create a SIFT object\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect and compute keypoints and descriptors for the ROI\n",
    "roi_keypoints, roi_descriptors = sift.detectAndCompute(gray_roi, None)\n",
    "\n",
    "# Draw keypoints on the ROI image\n",
    "roi_with_keypoints = cv2.drawKeypoints(roi, roi_keypoints, None)\n",
    "\n",
    "# Display the ROI image with keypoints\n",
    "cv2.imshow('ROI with Keypoints', roi_with_keypoints)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e86c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
