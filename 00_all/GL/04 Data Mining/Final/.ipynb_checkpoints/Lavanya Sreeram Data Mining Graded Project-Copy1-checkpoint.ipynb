{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1631f5",
   "metadata": {},
   "source": [
    "### Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca8c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858757a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Factor Analyzer installation may be required\n",
    "#!pip install factor-analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e397e",
   "metadata": {},
   "source": [
    "# 1 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca4e34",
   "metadata": {},
   "source": [
    "### 1.1 Data Set:\n",
    "\n",
    "Clustering: Read the data and perform basic analysis such as printing a few rows (head and tail), info, data summary, null values duplicate values, etc. (4)\n",
    "\n",
    "For this excercise the 'Clustering Clean Ads_Data-2.xlsx' shall be used provided as part of project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7031ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/lsreeram/Downloads/_/GL/04 Data Mining/Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df = pd.read_excel('Clustering Clean Ads_Data-2.xlsx')\n",
    "ads_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be74f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0765c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ads_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da773b59",
   "metadata": {},
   "source": [
    "Based on above description of data, it is evident that data is not scaled. Scaling shall be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6e10f9",
   "metadata": {},
   "source": [
    "Assigned Data types are good. Next, check for duplicates in dataset, followed by missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f425775",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccbc260",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9299d8",
   "metadata": {},
   "source": [
    "3 columns namely CTR, CPM, CPC have missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52628b3",
   "metadata": {},
   "source": [
    "### 1.2 Treating missing values:\n",
    "\n",
    "Clustering: Treat missing values in CPC, CTR and CPM using the formula given. (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3061712",
   "metadata": {},
   "source": [
    "Calculate the values of CPM, CPC, CTR based on below provided information:\n",
    "\n",
    "CPM = (Total Campaign Spend / Number of Impressions) * 1,000. Note that the Total Campaign Spend refers to the 'Spend' Column in the dataset and the Number of Impressions refers to the 'Impressions' Column in the dataset. \n",
    "\n",
    "CPC = Total Cost (spend) / Number of Clicks.  Note that the Total Cost (spend) refers to the 'Spend' Column in the dataset and the Number of Clicks refers to the 'Clicks' Column in the dataset. \n",
    "\n",
    "CTR = Total Measured Clicks / Total Measured Ad Impressions x 100. Note that the Total Measured Clicks refers to the 'Clicks' Column in the dataset and the Total Measured Ad Impressions refers to the 'Impressions' Column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf789505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cpm(x):\n",
    "    spend =ads_df.Spend\n",
    "    impressions=ads_df.Impressions\n",
    "    cpm = (spend/impressions)*1000\n",
    "    return cpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cpc(x):\n",
    "    spend =ads_df.Spend\n",
    "    clicks=ads_df.Clicks\n",
    "    cpc = spend/clicks\n",
    "    return cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e49407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ctr(x):\n",
    "    clicks=ads_df.Clicks\n",
    "    impressions=ads_df.Impressions\n",
    "    ctr = (clicks/impressions)*100\n",
    "    return ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d444abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df['CPM']= ads_df[['CPM']].apply(lambda x: calculate_cpm(x))\n",
    "ads_df['CPC']= ads_df[['CPC']].apply(lambda x: calculate_cpc(x))\n",
    "ads_df['CTR']= ads_df[['CTR']].apply(lambda x: calculate_ctr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fd983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ads_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_new_df = ads_df.drop(['Timestamp', 'InventoryType','Ad Type', 'Platform','Device Type', 'Format'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_new_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233429fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_new_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a1fc6",
   "metadata": {},
   "source": [
    "New dataset is created with relevant variables for clustering. There are no more missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65854e87",
   "metadata": {},
   "source": [
    "### 1. 3 Outliers\n",
    "Clustering: Check if there are any outliers. Do you think treating outliers is necessary for K-Means clustering? Based on your judgement decide whether to treat outliers and if yes, which method to employ. (As an analyst your judgement may be different from another analyst). (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c25be",
   "metadata": {},
   "source": [
    "Check for presence of outliers in each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128aa4c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "feature_list = ads_new_df.columns\n",
    "for i in range(len(feature_list)):\n",
    "    plt.subplot(3,5, i + 1)\n",
    "    sns.boxplot(y = ads_new_df[feature_list[i]], data = ads_new_df)\n",
    "    #plt.title('Boxplot of {}'.format(feature_list[i]))\n",
    "    plt.title(feature_list[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee77de",
   "metadata": {},
   "source": [
    "There are outliers in many features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b6ed6",
   "metadata": {},
   "source": [
    "A major problem with K-Means is that K-means is sensitive to outliers. What does this mean?\n",
    "\n",
    "Well, if there is a single point that is too far away from the rest, it will always be placed in its own one-point cluster.\n",
    "Such a data point is so far away from the rest of the data that it is destined to be in its own cluster. The remedy, just get rid of outliers prior to clustering.\n",
    "\n",
    "Alternatively, if you do the clustering and spot one-point clusters, remove them and cluster again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bfc104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(col):\n",
    "    Q1,Q3=col.quantile([0.25, 0.75])\n",
    "    IQR=Q3-Q1\n",
    "    lower_range=Q1-(1.5*IQR)\n",
    "    upper_range=Q3+(1.5*IQR)\n",
    "    return lower_range, upper_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc032aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ads_new_df.columns:\n",
    "    LL,UL=remove_outlier(ads_new_df[i])\n",
    "    ads_new_df[i] = np.where(ads_new_df[i] > UL, UL, ads_new_df[i])\n",
    "    ads_new_df[i] = np.where(ads_new_df[i] < LL, LL, ads_new_df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d320c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "for i in range(len(ads_new_df.columns)):\n",
    "    plt.subplot(3,5, i+1)\n",
    "    sns.boxplot(y = ads_new_df[ads_new_df.columns[i]], data = ads_new_df)\n",
    "    plt.title(ads_new_df.columns[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ac0d5",
   "metadata": {},
   "source": [
    "There are no outliers in the above boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b09c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_new_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb81556",
   "metadata": {},
   "source": [
    "### 1.4 Z-Score\n",
    "Clustering: Perform z-score scaling and discuss how it affects the speed of the algorithm. (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48473eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "#from scipy.stats import zscore\n",
    "ads_scaled_df = ads_new_df.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea18da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9904da72",
   "metadata": {},
   "source": [
    "### 1.5 Clustering\n",
    "\n",
    "Clustering: Perform Hierarchical by constructing a Dendrogram using WARD and Euclidean distance. (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ca874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "wardlink = linkage(ads_scaled_df, method='ward', metric='euclidean')\n",
    "dend = dendrogram(wardlink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef21a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show last p  merges, setting p-10\n",
    "dend = dendrogram(wardlink, truncate_mode='lastp', p=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55403cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign cluster to records using fcluster\n",
    "#Method1\n",
    "clusters = fcluster(wardlink, 5, criterion='maxclust')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ads_df['Hierarchical_Clusters']=clusters\n",
    "#ads_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d968295",
   "metadata": {},
   "source": [
    "### 1.6 Elbow Point\n",
    "Clustering: Make Elbow plot (up to n=10) and identify optimum number of clusters for k-means algorithm. (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94703cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.cluster import KMeans\n",
    "wss =[] \n",
    "for i in range(1,11):\n",
    "    KM = KMeans(n_clusters=i)\n",
    "    KM.fit(ads_scaled_df)\n",
    "    wss.append(KM.inertia_)\n",
    "wss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b9a4b",
   "metadata": {},
   "source": [
    "Most data can be captured in 5 clusters, plotting below to see elbow point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222c1c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(1,11), wss, marker='o', markerfacecolor='red', markersize=10)\n",
    "plt.xlabel('K (Number of Clusters)')\n",
    "plt.ylabel('Inertia Score')\n",
    "plt.title('Inertia vs K Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f581f",
   "metadata": {},
   "source": [
    "We have a very distinct elbow point here and generally distinct elbows rarely come out in actual data. The the optimum value of k can be 5 from above plot as inertia continuous to drop steeply at least till k=4.\n",
    "\n",
    "We can use silhouette score, which is another cluster quality measure, to choose the best k among 4–6. We can also take business inputs here to determine what would be a practical value of k.\n",
    "\n",
    "Once we have determined the value of k, we generate the final clustering object and save it for scoring process. We will also get the cluster labels for all the records and save it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c6c11",
   "metadata": {},
   "source": [
    "### 1.7 Silehoutte\n",
    "Clustering: Print silhouette scores for up to 10 clusters and identify optimum number of clusters. (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86611b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sil_df=pd.DataFrame()\n",
    "sil_scores = []\n",
    "sil_min_scores=[]\n",
    "print('Printing the Silhouette Scores for the k clusters below: ')\n",
    "print('')\n",
    "\n",
    "for i in range(2,11):\n",
    "    KM = KMeans(n_clusters=i)\n",
    "    KM.fit(ads_scaled_df)\n",
    "    labels =KM.labels_\n",
    "    \n",
    "    #Calculate and Print Silhoutte Score\n",
    "    sil_score = silhouette_score(ads_scaled_df,labels)\n",
    "    \n",
    "    print('Silhoutte Score for {0} clusters is: {1}'.format(i, sil_score))\n",
    "    sil_scores.append(sil_score)\n",
    "    \n",
    "    #Calculate and Print Silhouette Minimum Score:\n",
    "    sil_min_score = silhouette_samples(ads_scaled_df,labels).min()\n",
    "    sil_min_scores.append(sil_min_score)\n",
    "    \n",
    "    #Assign Cluster Silhouette Widths of K clusters to original dataframe\n",
    "\n",
    "    #sil_width = silhouette_samples(ads_scaled_df,labels)\n",
    "    #ads_df[i]=sil_width\n",
    "    \n",
    "    #Assign Cluster Labels of K Clusters to original datarame\n",
    "    #ads_df['Clusters_KMeans_{0}'.format(i)] = labels   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13723e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_min_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6db3db",
   "metadata": {},
   "source": [
    "The Silhouette scores are visualized in plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(2,11), sil_scores, marker='o', markerfacecolor='blue', markersize=10)\n",
    "plt.xlabel('K (Number of Clusters)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs K Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931e87b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sil_score = silhouette_score(ads_scaled_df,labels)\n",
    "sil_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c9d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_min = silhouette_samples(ads_scaled_df,labels).min()\n",
    "sil_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810416ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ads_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a15bec",
   "metadata": {},
   "source": [
    "### 1.8 Profiling\n",
    "\n",
    "Clustering: Profile the ads based on optimum number of clusters using silhouette score and your domain understanding [Hint: Group the data by clusters and take sum or mean to identify trends in Clicks, spend, revenue, CPM, CTR, & CPC based on Device Type. Make bar plots (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans k value determination\n",
    "k_means = KMeans(n_clusters=5)\n",
    "k_means.fit(ads_scaled_df)\n",
    "labels = k_means.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd6569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ads_df['Kmeans_Clusters']=labels\n",
    "ads_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93eecc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ads_df['Kmeans_Clusters'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65dd06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clust_profile = ads_df.drop(['Timestamp', 'InventoryType','Ad Type', 'Platform','Device Type', 'Format'], axis = 1)\n",
    "clust_profile=ads_df.groupby('Kmeans_Clusters').mean()\n",
    "clust_profile['freq']=ads_df['Kmeans_Clusters'].value_counts().sort_index()\n",
    "clust_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233fdee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_df.to_csv('Ads_Clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering for unique labels\n",
    " \n",
    "u_labels = np.unique(labels)\n",
    "\n",
    "#filter rows of original data\n",
    "filtered_label0 = ads_df[labels == 0]\n",
    "\n",
    "#filter rows of original data\n",
    "filtered_label2 = ads_df[labels == 2].values\n",
    " \n",
    "filtered_label8 = ads_df[labels == 4].values\n",
    "\n",
    "#Plotting the results\n",
    "plt.scatter(filtered_label2[:,0] , filtered_label2[:,1] , color = 'red')\n",
    "plt.scatter(filtered_label8[:,0] , filtered_label8[:,1] , color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6ec6c5",
   "metadata": {},
   "source": [
    "### 1.9 Clustering Conclusion\n",
    "Clustering: Conclude the project by providing summary of your learnings. (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c81dd",
   "metadata": {},
   "source": [
    "Refer to Business Report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff5344",
   "metadata": {},
   "source": [
    "# 2 PCA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69a795",
   "metadata": {},
   "source": [
    "### 2.1 Part 2 - PCA: Dataset\n",
    "    \n",
    "Read the data and perform basic checks like checking head, info, summary, nulls, and duplicates, etc. (4)\n",
    "\n",
    "For this excercise the 'PCA India Data_Census.xlsx' shall be used provided as part of project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61cf10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/lsreeram/Downloads/_/GL/04 Data Mining/Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21602ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('PCA India Data_Census.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4c90a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 61)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbb9bfee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Code</th>\n",
       "      <th>Dist.Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Area Name</th>\n",
       "      <th>No_HH</th>\n",
       "      <th>TOT_M</th>\n",
       "      <th>TOT_F</th>\n",
       "      <th>M_06</th>\n",
       "      <th>F_06</th>\n",
       "      <th>M_SC</th>\n",
       "      <th>...</th>\n",
       "      <th>MARG_CL_0_3_M</th>\n",
       "      <th>MARG_CL_0_3_F</th>\n",
       "      <th>MARG_AL_0_3_M</th>\n",
       "      <th>MARG_AL_0_3_F</th>\n",
       "      <th>MARG_HH_0_3_M</th>\n",
       "      <th>MARG_HH_0_3_F</th>\n",
       "      <th>MARG_OT_0_3_M</th>\n",
       "      <th>MARG_OT_0_3_F</th>\n",
       "      <th>NON_WORK_M</th>\n",
       "      <th>NON_WORK_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>Kupwara</td>\n",
       "      <td>7707</td>\n",
       "      <td>23388</td>\n",
       "      <td>29796</td>\n",
       "      <td>5862</td>\n",
       "      <td>6196</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1150</td>\n",
       "      <td>749</td>\n",
       "      <td>180</td>\n",
       "      <td>237</td>\n",
       "      <td>680</td>\n",
       "      <td>252</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>258</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>Badgam</td>\n",
       "      <td>6218</td>\n",
       "      <td>19585</td>\n",
       "      <td>23102</td>\n",
       "      <td>4482</td>\n",
       "      <td>3733</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>525</td>\n",
       "      <td>715</td>\n",
       "      <td>123</td>\n",
       "      <td>229</td>\n",
       "      <td>186</td>\n",
       "      <td>148</td>\n",
       "      <td>76</td>\n",
       "      <td>178</td>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>Leh(Ladakh)</td>\n",
       "      <td>4452</td>\n",
       "      <td>6546</td>\n",
       "      <td>10964</td>\n",
       "      <td>1082</td>\n",
       "      <td>1018</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>188</td>\n",
       "      <td>44</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Code  Dist.Code            State    Area Name  No_HH  TOT_M  TOT_F  \\\n",
       "0           1          1  Jammu & Kashmir      Kupwara   7707  23388  29796   \n",
       "1           1          2  Jammu & Kashmir       Badgam   6218  19585  23102   \n",
       "2           1          3  Jammu & Kashmir  Leh(Ladakh)   4452   6546  10964   \n",
       "\n",
       "   M_06  F_06  M_SC  ...  MARG_CL_0_3_M  MARG_CL_0_3_F  MARG_AL_0_3_M  \\\n",
       "0  5862  6196     3  ...           1150            749            180   \n",
       "1  4482  3733     7  ...            525            715            123   \n",
       "2  1082  1018     3  ...            114            188             44   \n",
       "\n",
       "   MARG_AL_0_3_F  MARG_HH_0_3_M  MARG_HH_0_3_F  MARG_OT_0_3_M  MARG_OT_0_3_F  \\\n",
       "0            237            680            252             32             46   \n",
       "1            229            186            148             76            178   \n",
       "2             89              3             34              0              4   \n",
       "\n",
       "   NON_WORK_M  NON_WORK_F  \n",
       "0         258         214  \n",
       "1         140         160  \n",
       "2          67          61  \n",
       "\n",
       "[3 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e43d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c623319",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c234c2",
   "metadata": {},
   "source": [
    "Observation: Data is not scaled already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44d988",
   "metadata": {},
   "source": [
    "### 2.2 Part 2 - PCA: EDA\n",
    "\n",
    "Perform detailed Exploratory analysis by creating certain questions like (i) Which state has highest gender ratio and which has the lowest? (ii) Which district has the highest & lowest gender ratio? (Example Questions). Pick 5 variables out of the given 24 variables below for EDA: No_HH, TOT_M, TOT_F, M_06, F_06, M_SC, F_SC, M_ST, F_ST, M_LIT, F_LIT, M_ILL, F_ILL, TOT_WORK_M, TOT_WORK_F, MAINWORK_M, MAINWORK_F, MAIN_CL_M, MAIN_CL_F, MAIN_AL_M, MAIN_AL_F, MAIN_HH_M, MAIN_HH_F, MAIN_OT_M, MAIN_OT_F\n",
    "\n",
    "(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dac1f0",
   "metadata": {},
   "source": [
    "SEX RATIO at BIRTH is the number of resident male live births (for a specific geography such as country, state or county for a specified time period, usually a calendar year) divided by the number of resident female live births (for the same geography and time period) and multiplied by 100 or 1,000. 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b8ae0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Area Name</th>\n",
       "      <th>TOT_F</th>\n",
       "      <th>TOT_M</th>\n",
       "      <th>F_LIT</th>\n",
       "      <th>M_LIT</th>\n",
       "      <th>TOT_WORK_F</th>\n",
       "      <th>TOT_WORK_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>Kupwara</td>\n",
       "      <td>29796</td>\n",
       "      <td>23388</td>\n",
       "      <td>11364</td>\n",
       "      <td>13381</td>\n",
       "      <td>3752</td>\n",
       "      <td>6723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>Badgam</td>\n",
       "      <td>23102</td>\n",
       "      <td>19585</td>\n",
       "      <td>7891</td>\n",
       "      <td>10513</td>\n",
       "      <td>4200</td>\n",
       "      <td>6982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>Leh(Ladakh)</td>\n",
       "      <td>10964</td>\n",
       "      <td>6546</td>\n",
       "      <td>5840</td>\n",
       "      <td>4534</td>\n",
       "      <td>4800</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State    Area Name  TOT_F  TOT_M  F_LIT  M_LIT  TOT_WORK_F  \\\n",
       "0  Jammu & Kashmir      Kupwara  29796  23388  11364  13381        3752   \n",
       "1  Jammu & Kashmir       Badgam  23102  19585   7891  10513        4200   \n",
       "2  Jammu & Kashmir  Leh(Ladakh)  10964   6546   5840   4534        4800   \n",
       "\n",
       "   TOT_WORK_M  \n",
       "0        6723  \n",
       "1        6982  \n",
       "2        2775  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eda = df.loc[:, ['State', 'Area Name','TOT_F', 'TOT_M', 'F_LIT' ,'M_LIT', 'TOT_WORK_F','TOT_WORK_M']]\n",
    "df_eda.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a90ae9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOT_F</th>\n",
       "      <th>TOT_M</th>\n",
       "      <th>F_LIT</th>\n",
       "      <th>M_LIT</th>\n",
       "      <th>TOT_WORK_F</th>\n",
       "      <th>TOT_WORK_M</th>\n",
       "      <th>No Of Districts</th>\n",
       "      <th>Gender Ratio M/F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andaman &amp; Nicobar Island</th>\n",
       "      <td>28691</td>\n",
       "      <td>18726</td>\n",
       "      <td>20237</td>\n",
       "      <td>15488</td>\n",
       "      <td>8483</td>\n",
       "      <td>9767</td>\n",
       "      <td>3</td>\n",
       "      <td>0.652679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andhra Pradesh</th>\n",
       "      <td>6097235</td>\n",
       "      <td>3274363</td>\n",
       "      <td>2678603</td>\n",
       "      <td>2372971</td>\n",
       "      <td>2833719</td>\n",
       "      <td>1674517</td>\n",
       "      <td>23</td>\n",
       "      <td>0.537024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arunachal Pradesh</th>\n",
       "      <td>88066</td>\n",
       "      <td>50582</td>\n",
       "      <td>45307</td>\n",
       "      <td>33965</td>\n",
       "      <td>41394</td>\n",
       "      <td>15841</td>\n",
       "      <td>16</td>\n",
       "      <td>0.574365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assam</th>\n",
       "      <td>2093432</td>\n",
       "      <td>1437268</td>\n",
       "      <td>1152979</td>\n",
       "      <td>1023294</td>\n",
       "      <td>705299</td>\n",
       "      <td>744397</td>\n",
       "      <td>27</td>\n",
       "      <td>0.686561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bihar</th>\n",
       "      <td>5405883</td>\n",
       "      <td>4025198</td>\n",
       "      <td>2197931</td>\n",
       "      <td>2408492</td>\n",
       "      <td>1464147</td>\n",
       "      <td>1524553</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            TOT_F    TOT_M    F_LIT    M_LIT  TOT_WORK_F  \\\n",
       "State                                                                      \n",
       "Andaman & Nicobar Island    28691    18726    20237    15488        8483   \n",
       "Andhra Pradesh            6097235  3274363  2678603  2372971     2833719   \n",
       "Arunachal Pradesh           88066    50582    45307    33965       41394   \n",
       "Assam                     2093432  1437268  1152979  1023294      705299   \n",
       "Bihar                     5405883  4025198  2197931  2408492     1464147   \n",
       "\n",
       "                          TOT_WORK_M  No Of Districts  Gender Ratio M/F  \n",
       "State                                                                    \n",
       "Andaman & Nicobar Island        9767                3          0.652679  \n",
       "Andhra Pradesh               1674517               23          0.537024  \n",
       "Arunachal Pradesh              15841               16          0.574365  \n",
       "Assam                         744397               27          0.686561  \n",
       "Bihar                        1524553               38          0.744596  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eda_1=df_eda.groupby('State').sum()\n",
    "df_eda_1['No Of Districts']=df_eda['State'].value_counts().sort_index()\n",
    "df_eda_1['Gender Ratio M/F'] = df_eda_1['TOT_M']/df_eda_1['TOT_F']\n",
    "df_eda_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7658b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_min = maxValueIndex = df_eda_1.idxmax()\n",
    "col_max = maxValueIndex = df_eda_1.idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec71f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9068fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum values of columns are at row index position :\n",
      "TOT_F               Uttar Pradesh\n",
      "TOT_M               Uttar Pradesh\n",
      "F_LIT               Uttar Pradesh\n",
      "M_LIT               Uttar Pradesh\n",
      "TOT_WORK_F          Uttar Pradesh\n",
      "TOT_WORK_M          Uttar Pradesh\n",
      "No Of Districts     Uttar Pradesh\n",
      "Gender Ratio M/F      Lakshadweep\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "maxValueIndex = df_eda_1.idxmax()\n",
    " \n",
    "print(\"Maximum values of columns are at row index position :\")\n",
    "print(maxValueIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5168b628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dadara & Nagar Havelli State/UT has Lowest Value of 10831 for TOT_F column\n",
      "Uttar Pradesh State/UT has Highest Value of 12023885 for TOT_F column\n",
      " \n",
      "Dadara & Nagar Havelli State/UT has Lowest Value of 6982 for TOT_M column\n",
      "Uttar Pradesh State/UT has Highest Value of 9043969 for TOT_M column\n",
      " \n",
      "Dadara & Nagar Havelli State/UT has Lowest Value of 5308 for F_LIT column\n",
      "Uttar Pradesh State/UT has Highest Value of 5574752 for F_LIT column\n",
      " \n",
      "Dadara & Nagar Havelli State/UT has Lowest Value of 5119 for M_LIT column\n",
      "Uttar Pradesh State/UT has Highest Value of 6016402 for M_LIT column\n",
      " \n",
      "Lakshadweep State/UT has Lowest Value of 1780 for TOT_WORK_F column\n",
      "Uttar Pradesh State/UT has Highest Value of 2972243 for TOT_WORK_F column\n",
      " \n",
      "Dadara & Nagar Havelli State/UT has Lowest Value of 3138 for TOT_WORK_M column\n",
      "Uttar Pradesh State/UT has Highest Value of 3710433 for TOT_WORK_M column\n",
      " \n",
      "Chandigarh State/UT has Lowest Value of 1 for No Of Districts column\n",
      "Uttar Pradesh State/UT has Highest Value of 71 for No Of Districts column\n",
      " \n",
      "Andhra Pradesh State/UT has Lowest Value of 0.5370242413159407 for Gender Ratio M/F column\n",
      "Lakshadweep State/UT has Highest Value of 0.8680611968589222 for Gender Ratio M/F column\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in df_eda_1.columns:\n",
    "    \n",
    "    min_val=df_eda_1[i].min()\n",
    "    max_val=df_eda_1[i].max()\n",
    "    \n",
    "    min_ind = df_eda_1[i].idxmin()    \n",
    "    max_ind = df_eda_1[i].idxmax()    \n",
    "    print(\"{1} State/UT has Lowest Value of {2} for {0} column\".format(i,min_ind,min_val))\n",
    "    print(\"{1} State/UT has Highest Value of {2} for {0} column\".format(i,max_ind,max_val))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a72415",
   "metadata": {},
   "source": [
    "(i) Which state has highest gender ratio and which has the lowest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd82695",
   "metadata": {},
   "source": [
    "Andhra Pradesh State/UT has Lowest Value of 0.5370242413159407 for Gender Ratio M/F column\n",
    "Lakshadweep State/UT has Highest Value of 0.8680611968589222 for Gender Ratio M/F column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214594a",
   "metadata": {},
   "source": [
    "(ii) Which district has the highest & lowest gender ratio?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f937a0",
   "metadata": {},
   "source": [
    "### 2.3 Part 2 - PCA: Outliers\n",
    "\n",
    "We choose not to treat outliers for this case. Do you think that treating outliers for this case is necessary? (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e2d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pca = df.drop(['State', 'Area Name', 'Dist.Code', 'State Code'], axis=1)\n",
    "df_pca.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb62ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for presence of outliers in each feature\n",
    "plt.figure(figsize = (20,16))\n",
    "feature_list = df_pca.columns\n",
    "for i in range(len(feature_list)):\n",
    "    plt.subplot(5,12, i + 1)\n",
    "    sns.boxplot(y = df_pca[feature_list[i]], data = df_pca)\n",
    "    plt.title('{}'.format(feature_list[i]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a86d6b",
   "metadata": {},
   "source": [
    "Z-score is a variation of scaling that represents the number of standard deviations away from the mean. You would use z-score to ensure your feature distributions have mean = 0 and std = 1. It's useful when there are a few outliers, but not so extreme that you need clipping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd8851f",
   "metadata": {},
   "source": [
    "### 2.4 Part 2 - PCA: Data Scaling\n",
    "    \n",
    "Scale the Data using z-score method. Does scaling have any impact on outliers? Compare boxplots before and after scaling and comment.    (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "from scipy.stats import zscore\n",
    "df_pca_scaled = df_pca.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the data post scaling\n",
    "df_pca_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f994a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for presence of correlations\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(df_pca_scaled.corr(), annot=True,fmt='.2f');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe877c",
   "metadata": {},
   "source": [
    "### 2.5 Part 2 - PCA: Perform PCA \n",
    "Perform all the required steps for PCA (use sklearn only) Create the covariance Matrix Get eigen values and eigen vector.\n",
    "(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm the statistical significance of correlations\n",
    "#H0: Correlations are not significant, H1: There are significant correlations\n",
    "#Reject H0 if p-value < 0.05\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "chi_square_value,p_value=calculate_bartlett_sphericity(df_pca_scaled)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm the adequacy of sample size. \n",
    "#Note: Above 0.7 is good, below 0.5 is not acceptable\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "kmo_all,kmo_model=calculate_kmo(df_pca_scaled)\n",
    "kmo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA taking all features\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=57, random_state=123)\n",
    "pca_transformed = pca.fit_transform(df_pca_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91eff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract eigen vectors\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the eigen values\n",
    "#Note: This is always returned in descending order\n",
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f950e",
   "metadata": {},
   "source": [
    "### 2.6 Part 2 - PCA: Identify PCA\n",
    "\n",
    "Identify the optimum number of PCs (for this project, take at least 90% explained variance). Show Scree plot. (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba3374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create a scree plot\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.lineplot(y=pca.explained_variance_ratio_ ,x=range(1,58),marker='o')\n",
    "plt.xlabel('Number of Components',fontsize=10)\n",
    "plt.ylabel('Variance Explained',fontsize=10)\n",
    "plt.title('Scree Plot',fontsize=12)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40814fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check the cumlative explained variance ratio to find a cut off for selecting the number of PCs\n",
    "exp_var=np.cumsum(pca.explained_variance_ratio_)\n",
    "exp_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc2d61",
   "metadata": {},
   "source": [
    "### 2.7 Part 2 - PCA: Inferences\n",
    "\n",
    "Compare PCs with Actual Columns and identify which is explaining most variance. Write inferences about all the Principal components in terms of actual variables. (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08400c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe containing the loadings or coefficients of all PCs\n",
    "df_extracted_loadings = pd.DataFrame(pca.components_.T, \n",
    "                                     columns = ['PC1','PC2', 'PC3', 'PC4', 'PC5', 'PC6','PC7', 'PC8', 'PC9', 'PC10',\n",
    "                                               'PC11','PC12', 'PC13', 'PC14', 'PC15', 'PC16','PC17', 'PC18', 'PC19', 'PC20',\n",
    "                                               'PC21','PC22', 'PC23', 'PC24', 'PC25', 'PC26','PC27', 'PC28', 'PC29', 'PC30',\n",
    "                                               'PC31','PC32', 'PC33', 'PC34', 'PC35', 'PC36','PC37', 'PC38', 'PC39', 'PC40',\n",
    "                                               'PC41','PC42', 'PC43', 'PC44', 'PC45', 'PC46','PC47', 'PC48', 'PC49', 'PC50',\n",
    "                                               'PC51','PC52', 'PC53', 'PC54', 'PC55', 'PC56','PC57'],\n",
    "                                    index = df_pca_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the PCs basis cumulative explained variance\n",
    "df_selected = df_extracted_loadings[['PC1','PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check as to how the original features matter to each PC\n",
    "#Note: Here we are only considering the absolute values\n",
    "plt.figure(figsize = (20,8))\n",
    "for i in range(len(df_selected.columns)):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    abs(df_selected[df_selected.columns[i]]).T.sort_values(ascending = False).plot.bar()\n",
    "    plt.yticks(np.arange(0,1.2,.2))\n",
    "    plt.title('Abs. loadings of {}'.format(df_selected.columns[i]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a084dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare how the original features influence various PCs\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.heatmap(abs(df_selected), annot = True, cmap = 'Blues',fmt = '.2f');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to calculate PC scores we need loadings, below:\n",
    "df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc471b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...and we need the original scaled features\n",
    "df_pca_scaled.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850cdd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to perform a dot product between the loadings and features to obtain the scores\n",
    "for i in df_selected.columns:\n",
    "    pc_score = np.dot(df_selected[i], df_pca_scaled.iloc[0])\n",
    "    print(round(pc_score, 6), end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb293a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above step involves a lot of hard work. Let's do it the easier way\n",
    "#Extract the required(as per the cumulative explained variance) number of PCs\n",
    "pca = PCA(n_components=7, random_state=123)\n",
    "pca_final = pca.fit_transform(df_pca_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b5b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Just create a dataframe out of fit_transformed scaled data above\n",
    "pca_final_df = pd.DataFrame(pca_final, columns = df_selected.columns)\n",
    "pca_final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for presence of correlations among the PCs\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(pca_final_df.corr(), annot=True,fmt='.2f');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506e7ea",
   "metadata": {},
   "source": [
    "### 2.8 Part 2 - PCA: PCA Equation\n",
    "\n",
    "Write linear equation for first PC. (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,57):\n",
    "    print(\"(\",np.round(pca.components_[0][i],2),\")\",'*',df_pca_scaled.columns[i], end=' + ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6891559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
