{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d301f037",
   "metadata": {},
   "source": [
    "https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c50493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\lsreeram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lsreeram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words') ##Change\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#importing libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import bs4 as BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c95706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [3]\n",
      "Born in Hamilton, Ardern grew up in Morrinsville and Murupara. [5] After negotiations, New Zealand First chose to enter a minority coalition government with Labour, supported by the Green Party, with Ardern as prime minister. [8]\n",
      "Ardern describes herself as a social democrat and a progressive. [21]\n",
      "Ardern was born on 26 July 1980 in Hamilton, New Zealand. [30]\n",
      "She joined the Labour Party at the age of 17. Accordingly, Ardern returned from London to campaign full-time. [56] She was confirmed as Labour's candidate at a meeting on 22 January. [57][58] Ardern won a landslide victory, gaining 77 per cent of votes cast in the preliminary results. [64] At 37, Ardern became the youngest leader of the Labour Party in its history. [86] Ardern named Peters as deputy prime minister and Minister of Foreign Affairs. It is that simple. \"[277] She supports compulsory study of the MƒÅori language in schools. I think you can hold both views, and I do. Nelson. [313]\n",
      "Ardern is a second cousin of Hamish McDouall, former mayor of Whanganui. [329]\n"
     ]
    }
   ],
   "source": [
    "#fetching the content from the URL\n",
    "fetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Jacinda_Ardern')\n",
    "\n",
    "article_read = fetched_data.read()\n",
    "\n",
    "#parsing the URL content and storing in a variable\n",
    "article_parsed = BeautifulSoup.BeautifulSoup(article_read,'html.parser')\n",
    "\n",
    "#returning <p> tags\n",
    "paragraphs = article_parsed.find_all('p')\n",
    "\n",
    "article_content = ''\n",
    "\n",
    "#looping through the paragraphs and adding them to the variable\n",
    "for p in paragraphs:  \n",
    "    article_content += p.text\n",
    "\n",
    "\n",
    "def _create_dictionary_table(text_string) -> dict:\n",
    "   \n",
    "    #removing stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    #reducing words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    #creating dictionary for the word frequency table\n",
    "    frequency_table = dict()\n",
    "    for wd in words:\n",
    "        wd = stem.stem(wd)\n",
    "        if wd in stop_words:\n",
    "            continue\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "\n",
    "    return frequency_table\n",
    "\n",
    "\n",
    "def _calculate_sentence_scores(sentences, frequency_table) -> dict:   \n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_weight = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        for word_weight in frequency_table:\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "                if sentence[:7] in sentence_weight:\n",
    "                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\n",
    "                else:\n",
    "                    sentence_weight[sentence[:7]] = frequency_table[word_weight]\n",
    "\n",
    "        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words\n",
    "\n",
    "       \n",
    "\n",
    "    return sentence_weight\n",
    "\n",
    "def _calculate_average_score(sentence_weight) -> int:\n",
    "   \n",
    "    #calculating the average score for the sentences\n",
    "    sum_values = 0\n",
    "    for entry in sentence_weight:\n",
    "        sum_values += sentence_weight[entry]\n",
    "\n",
    "    #getting sentence average value from source text\n",
    "    average_score = (sum_values / len(sentence_weight))\n",
    "\n",
    "    return average_score\n",
    "\n",
    "def _get_article_summary(sentences, sentence_weight, threshold):\n",
    "    sentence_counter = 0\n",
    "    article_summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] >= (threshold):\n",
    "            article_summary += \" \" + sentence\n",
    "            sentence_counter += 1\n",
    "\n",
    "    return article_summary\n",
    "\n",
    "def _run_article_summary(article):\n",
    "    \n",
    "    #creating a dictionary for the word frequency table\n",
    "    frequency_table = _create_dictionary_table(article)\n",
    "\n",
    "    #tokenizing the sentences\n",
    "    sentences = sent_tokenize(article)\n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_scores = _calculate_sentence_scores(sentences, frequency_table)\n",
    "\n",
    "    #getting the threshold\n",
    "    threshold = _calculate_average_score(sentence_scores)\n",
    "\n",
    "    #producing the summary\n",
    "    article_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold)\n",
    "\n",
    "    return article_summary\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    summary_results = _run_article_summary(article_content)\n",
    "    print(summary_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0af16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
